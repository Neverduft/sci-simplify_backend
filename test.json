{
    "section_titles": [
        "1 INTRODUCTION",
        "2 RELATED WORK",
        "3 USER-SPECIFIC AESTHETIC RANKING FRAMEWORK",
        "4 EXPERIMENTS",
        "5 CONCLUSION AND FUTURE WORK"
    ],
    "sections": [
        "The proliferation of social networks and mobile devices with cameras has led to an explosive increase in the number of digital images. This has generated large personal photograph datasets for maintaining beautiful memories. However, the organization of an ideal personal album or collection manually from such massive number of images is onerous, and this task is always time-consuming and challenging. The major problem underlying this challenge is the accurate recognition of the personal aesthetic preference of different users. In this paper, we study how to automatically assess the aesthetic characteristics of images through taking into account the user's preference in a simple interactive way. In recent years, plenty of methods have been proposed to measure the aesthetic quality of photographs. Most researchers focus their attention on selecting and setting universal descriptors derived from high quality images. Based on the assumption that high quality images share certain common aesthetic rules, massive hand-crafted low level visual features and high level aesthetic attributes have been proposed. However, traditional hand-crafted visual features are limited and restrictive due to the following reasons: 1) These man-made visual features are the approximations of aesthetic rules, failing to fully capture the aesthetic abstract. 2) The universal visual features lack of consideration for subjectivity and personal preference of different users. Recently, instead of using traditional hand-crafted visual features, the state-of-art feature extraction technique based on deep learning has been involved to evaluate the aesthetic quality of images. Compared with those traditional methods, the most notable difference is that the deep features of the input images could be extracted automatically without making any artificial approximations of the aesthetic rules. However, most of above work pay their attention on the task of binary classification without considering the subjectivity and personal preference of diverse individuals. In [24], Ren et al. try to address this personalized aesthetics problem by showing that individual's aesthetic preferences exhibit strong correlations with image content and aesthetic attributes, and the deviation of individual's perception from generic image aesthetics is predictable. They propose a new approach to personalized aesthetics learning that can be trained even with a small set of annotated images from one user. However, since one user's preference is highly subjective and his/her choice one time is occasional, a small set of annotated images is insufficient to fully represent his or her personal preference. To solve the above problems, in this paper, we propose a novel and interactive user-friendly aesthetic ranking framework, called User-specific Aesthetic Ranking (USAR), which consists of three modules: primary personalized ranking (PPR), interaction stage (IS) and user-specific aesthetic distribution (USAD). The proposed framework takes as input a series of photos that users prefer, and produces as output a reliable, user-specific aesthetic distribution matching with user's preference. In the module of PPR, a unique and exclusive dataset will be constructed interactively to describe the preference of one individual by retrieving the most similar images with regard to those specified by users. This is based on the fact that the aesthetic preference of one user will remain unchanged for a long time. The powerful Deep Convolutional Neural Network is involved and optimized to retrieve those content similar images through several amounts of interactions in the module of IS. Based on this unique user-specific dataset and sufficient well-designed aesthetic attributes, a customized aesthetic distribution model will be learned in the module of USAD, which concatenates both personalized preference and photography rules. Given an input image, its corresponding aesthetic distribution will be computed by USAD. After that, the correlation coefficient between one user's specific aesthetic distribution and that of input image can be obtained. The larger the coefficient is, the higher aesthetic score and ranking is. We conduct extensive experiments and user studies on two large-scale public datasets, and demonstrate that our framework outperforms those work based on conventional aesthetic assessment or ranking model. The contributions of this paper mainly focus on the following aspects. • We propose a novel and user-friendly aesthetic ranking framework via powerful deep neural network and a small amount of interaction, which can automatically rank the aesthetic quality of images in accordance with user's preference. • We propose an efficient and limited interactive method to construct a unique and exclusive dataset to represent the aesthetic preference of one individual, which can overcome the problem of user's subjective preference and occasional choice. • We propose a customized aesthetic distribution model based on a unique user-specific dataset and sufficient well-designed aesthetic attributes, which concatenates both user's personalized preference and aesthetic rules.",
        "User-specific aesthetic quality ranking mainly concerns two important problems: how to evaluate the aesthetic quality of images and how to collect user-specific images. In this section, we first review related aesthetic quality assessment work, then discuss the problem concerning personalized image searching and ranking, which is used to collect user-specific images. The previous work mainly focus on hand-crafted visual features that all high-quality images may share. Extensive experiments have been conducted with low-level visual features and high-level features combinations. Some researchers were not satisfied with the results of low-level visual features, so they have turned their attention to the combination of high-level features. Although hand-crafted features play a certain role in assessing the image quality, it is a man-made approximation of the abstract aesthetic rules and may fail to capture the full diversity and beauty of a photographic image. In recent years, with the rise of deep learning, the extraction of deep features has gradually become popular for the task of image quality assessment. Despite the high accuracy of the binary classification tasks that deep neural network achieves, it can not extract the meaning of aesthetics in the absolute sense and understand personal preference. Ren et al. tried to address this personalized aesthetics problem by showing that individual's aesthetic preferences exhibit strong correlations with content and aesthetic attributes, and the deviation of individual's perception from generic image aesthetics is predictable. They proposed a new approach to personalized aesthetics learning that can be trained even with a small set of annotated images from a user, but the ability to characterize user's preference is limited and unstable. Our proposed User-specific Aesthetic Ranking (USAR) framework tries to address above problems. To overcome the shortcomings of low or high level visual features, a powerful and iterative optimized AlexNet is deployed to capture the full diversity of user selected images. Aiming at the problem of unstable personalized ranking of images, we try to construct a unique and exclusive dataset with user's interactions. Based on the unique user-specific dataset and sufficient well-designed aesthetic attributes, a customized aesthetic distribution model is learned, which concatenates both personalized preference and photography rules.",
        "In this paper, we propose a user-specific aesthetic ranking framework by using a massive image dataset via AlexNet, which consists of three modules: 1) Primary personalized ranking, 2) Interaction stage and 3) User-specific aesthetic ranking. Given a set of preferred images, we first extract their content features for further retrieval of similar images from the whole aesthetic database and construct a retrieval set. Then a primary personalized ranking RPPR is generated from the primary personalized ranking module. In order to overcome the instability suffered from the direct use of a small amount of samples, i.e., the user-specific images, we perform refining strategy by asking user to interact with the primary ranking images and treat them as the ground-truth, which are subsequently sent to our style-specific classifier to generate a user-specific aesthetic distribution DU SAR. During the testing stage, the learned ranking module outputs the testing distribution Dtest. Consequently, user-specific aesthetic ranking is obtained by calculating the correlation coefficients between DU SAR and Dtest.",
        "In this section, we introduce how we conduct the experiment on two large scale public datasets and the comparison with other state-of-art methods.",
        "We propose a novel and user-specific aesthetic ranking model which first combines the results of deep neural network with individual preference to explore a new overlap between the subjective feeling of the users and the aesthetic abstract. In our proposed ranking framework, we construct a reliable ranking framework consisting of Primary personalized ranking, Interaction stage and User-specific aesthetic distribution. Experimental results on two large datasets demonstrate the effectiveness and efficiency of our approach."
    ]
}